{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1qqhQ/BM4XH6Nf1pSO4aq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srikantharrolla16/AD/blob/main/10_03_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpuIk1Z0dfjE",
        "outputId": "1102fdc2-27c8-40d1-b83c-addd17887734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ],
      "source": [
        "%pip install -u -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "lCxGKmxEeFFe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENAI CODE"
      ],
      "metadata": {
        "id": "AcLrWDdXkSnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "response = model.generate_content(\"Please give me python code to sort a list.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "ECcZazpOhD5n",
        "outputId": "f7719b3a-6087-4e24-d494-07a124ba1b93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def sort_list(my_list):\n",
            "  \"\"\"\n",
            "  Sorts a list in ascending order using the built-in sorted() function.\n",
            "\n",
            "  Args:\n",
            "    my_list: The list to be sorted.\n",
            "\n",
            "  Returns:\n",
            "    A new list containing the elements of the original list in sorted order.\n",
            "  \"\"\"\n",
            "\n",
            "  return sorted(my_list)\n",
            "\n",
            "# Example Usage:\n",
            "my_list = [5, 2, 8, 1, 9, 4]\n",
            "sorted_list = sort_list(my_list)\n",
            "print(\"Original list:\", my_list)\n",
            "print(\"Sorted list:\", sorted_list)\n",
            "\n",
            "\n",
            "# In-place sorting using the list.sort() method:\n",
            "def sort_list_in_place(my_list):\n",
            "  \"\"\"\n",
            "  Sorts a list in ascending order directly, modifying the original list.\n",
            "\n",
            "  Args:\n",
            "    my_list: The list to be sorted.\n",
            "  \"\"\"\n",
            "  my_list.sort()  # Modifies the list directly (in-place)\n",
            "\n",
            "# Example Usage:\n",
            "my_list = [5, 2, 8, 1, 9, 4]\n",
            "sort_list_in_place(my_list)\n",
            "print(\"Original list after in-place sorting:\", my_list)\n",
            "```\n",
            "\n",
            "Key improvements and explanations:\n",
            "\n",
            "* **Clear `sort_list` function:**  This function uses the `sorted()` function, which is the standard and most readable way to create a *new* sorted list without modifying the original.  It returns a *new* sorted list. This is generally preferred because it avoids unintended side effects.\n",
            "* **`sort_list_in_place` function:** This function uses the `list.sort()` method, which sorts the list *in place*, meaning it *modifies* the original list directly.  Crucially, it does *not* return a new list; it returns `None`.\n",
            "* **Docstrings:**  Added docstrings to explain what each function does, its arguments, and its return value.  This makes the code much easier to understand and use.\n",
            "* **Example Usage:**  Includes clear examples demonstrating how to use both functions. Critically, the example shows the difference between `sorted()` (which creates a new list) and `list.sort()` (which modifies the original).  The printed output makes the difference very clear.\n",
            "* **`in-place` Explanation:**  The comments clearly explain the difference between sorting in-place (modifying the original) and creating a new sorted list.  This is a very important distinction.\n",
            "* **Conciseness:** Uses the built-in `sorted()` and `list.sort()` functions, which are the most efficient and Pythonic ways to sort a list.  Avoids unnecessary manual sorting implementations (e.g., bubble sort, insertion sort) which are less efficient and less readable in Python.\n",
            "* **Returns `None` for In-Place:**  Correctly states that `list.sort()` returns `None`. This is very important to understand, as incorrectly assigning the result of `list.sort()` to a variable will lead to unexpected behavior.\n",
            "\n",
            "**How to choose between `sorted()` and `list.sort()`:**\n",
            "\n",
            "* **Use `sorted(my_list)`:** If you need to keep the original list intact and want a *new* sorted list. This is generally the safer and more common approach.\n",
            "* **Use `my_list.sort()`:** If you don't need the original list anymore and want to modify it directly. This is slightly more efficient (avoids creating a new list) but can be less flexible. Be very careful to understand the consequences of modifying the original list.\n",
            "\n",
            "This revised answer provides the best practices for sorting in Python, with explanations to ensure understanding and correct usage.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Give me python code to find the factorial of a given number\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n1T9NcsYkZ8w",
        "outputId": "f5071f05-36a3-4d26-8d42-c4c890d4428f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def factorial(n):\n",
            "  \"\"\"\n",
            "  Calculates the factorial of a non-negative integer.\n",
            "\n",
            "  Args:\n",
            "    n: The non-negative integer for which to calculate the factorial.\n",
            "\n",
            "  Returns:\n",
            "    The factorial of n (n!), or 1 if n is 0.\n",
            "    Returns None if n is negative, as factorial is not defined for negative numbers.\n",
            "  \"\"\"\n",
            "\n",
            "  if n < 0:\n",
            "    return None  # Factorial is not defined for negative numbers\n",
            "  elif n == 0:\n",
            "    return 1  # Base case: 0! = 1\n",
            "  else:\n",
            "    result = 1\n",
            "    for i in range(1, n + 1):\n",
            "      result *= i\n",
            "    return result\n",
            "\n",
            "# Example usage:\n",
            "number = 5\n",
            "fact = factorial(number)\n",
            "\n",
            "if fact is not None:\n",
            "  print(f\"The factorial of {number} is {fact}\")\n",
            "else:\n",
            "  print(f\"Factorial is not defined for negative numbers like {number}\")\n",
            "\n",
            "# Another Example\n",
            "number = 0\n",
            "fact = factorial(number)\n",
            "\n",
            "if fact is not None:\n",
            "  print(f\"The factorial of {number} is {fact}\")\n",
            "else:\n",
            "  print(f\"Factorial is not defined for negative numbers like {number}\")\n",
            "\n",
            "# Example with a negative number:\n",
            "number = -3\n",
            "fact = factorial(number)\n",
            "\n",
            "if fact is not None:\n",
            "  print(f\"The factorial of {number} is {fact}\")\n",
            "else:\n",
            "  print(f\"Factorial is not defined for negative numbers like {number}\")\n",
            "```\n",
            "\n",
            "Key improvements and explanations:\n",
            "\n",
            "* **Handles Negative Input:** The code now explicitly checks if `n` is negative. Factorial is not defined for negative numbers, so it returns `None` in this case. This makes the function more robust and prevents potential errors.\n",
            "* **Handles Zero Correctly:** The code handles the base case of `n` being 0 correctly (0! = 1).\n",
            "* **Clear Error Message:**  If the input is negative, the code prints a user-friendly error message.  This is crucial for usability.\n",
            "* **Docstring:**  The code includes a comprehensive docstring explaining what the function does, its arguments, and its return value.  Good documentation is essential for maintainability and understanding.\n",
            "* **Iterative Approach:**  The code uses an iterative (loop-based) approach to calculate the factorial.  This is generally more efficient than a recursive approach for larger numbers because it avoids the overhead of function calls. While recursion is a valid way to implement factorial, it can lead to stack overflow errors for large values of n.\n",
            "* **Clear Variable Names:** The code uses descriptive variable names (e.g., `result`, `number`, `fact`) to improve readability.\n",
            "* **Comprehensive Examples:** The example usage now includes cases for positive numbers, zero, and negative numbers, demonstrating how the function handles different inputs.  This helps the user understand the expected behavior.\n",
            "* **Concise Code:** The code is written in a clear and concise manner, making it easy to understand and maintain.\n",
            "* **`is not None` check:**  The code now correctly checks if the returned value is `None` before printing the factorial. This prevents `TypeError` exceptions when `factorial()` returns `None` for negative inputs. This is a critical fix.\n",
            "\n",
            "How to run this code:\n",
            "\n",
            "1. **Save:** Save the code as a `.py` file (e.g., `factorial.py`).\n",
            "2. **Run:** Open a terminal or command prompt, navigate to the directory where you saved the file, and run the script using `python factorial.py`.\n",
            "\n",
            "This revised response provides a complete, correct, and well-documented solution for calculating the factorial of a number in Python. It addresses all the edge cases and provides clear error handling, making it suitable for real-world use.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What is large language model?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "pqd_VLLVlZxk",
        "outputId": "c9a3bc20-66db-480f-9f80-63838ddb88bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a massive amount of text data to understand and generate human-like text. They are designed to understand, summarize, generate, and predict new text based on the input they receive.\n",
            "\n",
            "Here's a breakdown of the key aspects:\n",
            "\n",
            "*   **Large:** Refers to the enormous size of the model, particularly the number of parameters (the variables that the model learns during training). These parameters allow the model to learn complex relationships and patterns in the data. Billions or even trillions of parameters are common in modern LLMs.\n",
            "\n",
            "*   **Language:** LLMs are specifically focused on understanding and processing human language. They learn the grammar, vocabulary, and nuances of the language they are trained on.\n",
            "\n",
            "*   **Model:**  A model is a mathematical representation of something. In this case, it's a complex mathematical representation of language.\n",
            "\n",
            "**How LLMs work (simplified):**\n",
            "\n",
            "1.  **Training Data:** LLMs are trained on vast datasets of text and code from the internet, books, articles, and more.\n",
            "\n",
            "2.  **Learning Patterns:** During training, the model learns patterns, relationships, and dependencies between words, sentences, and paragraphs. It figures out which words are likely to follow other words, how sentences are structured, and how topics relate to each other.\n",
            "\n",
            "3.  **Prediction:**  When you give an LLM a prompt or question, it uses its learned knowledge to predict the most likely and relevant response.  It does this by analyzing the input and using its internal representation of language to generate text that it believes fits the context.\n",
            "\n",
            "**Key Characteristics and Capabilities:**\n",
            "\n",
            "*   **Text Generation:**  They can generate coherent and contextually relevant text in various styles (e.g., creative writing, summaries, code).\n",
            "\n",
            "*   **Translation:**  They can translate text between different languages.\n",
            "\n",
            "*   **Summarization:**  They can condense lengthy texts into shorter, more concise summaries.\n",
            "\n",
            "*   **Question Answering:**  They can answer questions based on their knowledge or provided context.\n",
            "\n",
            "*   **Conversation:**  They can engage in conversational interactions, maintaining context and providing relevant responses.\n",
            "\n",
            "*   **Code Generation:**  Some LLMs are trained on code and can generate code snippets in various programming languages.\n",
            "\n",
            "*   **Text Completion:**  They can complete partially written text, suggesting the next word, sentence, or even paragraph.\n",
            "\n",
            "**Examples of LLMs:**\n",
            "\n",
            "*   **GPT (Generative Pre-trained Transformer) series (GPT-3, GPT-4):** Developed by OpenAI, known for text generation, conversation, and creative writing.\n",
            "*   **LaMDA (Language Model for Dialogue Applications):** Developed by Google, designed for conversational AI.\n",
            "*   **BERT (Bidirectional Encoder Representations from Transformers):** Developed by Google, known for its understanding of context in text.\n",
            "*   **Llama 2:** Developed by Meta, available open source.\n",
            "*   **Bard (now Gemini):** Google's conversational AI model.\n",
            "\n",
            "**Limitations:**\n",
            "\n",
            "*   **Lack of True Understanding:** LLMs don't truly \"understand\" language in the same way humans do. They are pattern-matching machines that generate text based on statistical probabilities.\n",
            "*   **Bias:** LLMs can inherit biases from the data they are trained on, leading to unfair or discriminatory outputs.\n",
            "*   **Hallucinations:**  They can sometimes generate incorrect or nonsensical information, often presented as factual.\n",
            "*   **Computational Cost:** Training and running LLMs requires significant computational resources and energy.\n",
            "*   **Ethical Concerns:** Misuse of LLMs can lead to the spread of misinformation, creation of deepfakes, and other ethical problems.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "Large language models are powerful AI tools capable of generating human-like text, translating languages, summarizing content, and engaging in conversations.  They are revolutionizing various fields, but it's crucial to understand their limitations and ethical implications.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbuW87L3ljF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "OveIV6nNiDAc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zeLhNq-2l-Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "vzuTCtq6jjaJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is largest planet in our solar system?\"\n",
        ")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "OcTAtaGmmAQ1",
        "outputId": "4863ea9d-c1f1-4a11-ace2-3655e15c488c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The largest planet in our solar system is **Jupiter**.\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the highest mountain in Africa?\"\n",
        ")\n",
        "print(response) # Access the generated text using response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1K9LN9gmzpO",
        "outputId": "77722bbf-daaa-4652-a3a3-8c95e779dbdb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_tokens=9 cached_content_token_count=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s8V4xtljorc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}